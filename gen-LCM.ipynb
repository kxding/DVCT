{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-14T06:26:34.031644600Z",
     "start_time": "2024-05-14T06:26:32.580568900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/vct/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from diffusers import LCMScheduler\n",
    "from diffusers import DiffusionPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce6ad697bba6447fb8f799ffa53b90a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "/root/autodl-tmp/LCM does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//root/autodl-tmp/LCM/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m model_or_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/root/autodl-tmp/LCM\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m LCMScheduler\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_or_name, subfolder\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscheduler\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mDiffusionPipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_or_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscheduler\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# 设置随机种子\u001B[39;00m\n\u001B[1;32m     12\u001B[0m seed \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/vct/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/vct/lib/python3.8/site-packages/diffusers/pipelines/pipeline_utils.py:819\u001B[0m, in \u001B[0;36mDiffusionPipeline.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    816\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m passed_class_obj[name]\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    818\u001B[0m     \u001B[38;5;66;03m# load sub model\u001B[39;00m\n\u001B[0;32m--> 819\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_sub_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    820\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    821\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    822\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimportable_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimportable_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpipelines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipelines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_pipeline_module\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_pipeline_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpipeline_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipeline_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprovider\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprovider\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43msess_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msess_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_state_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_state_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_variants\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_variants\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvariant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    838\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcached_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcached_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    840\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoaded \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m as \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` subfolder of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m     )\n\u001B[1;32m    844\u001B[0m init_kwargs[name] \u001B[38;5;241m=\u001B[39m loaded_sub_model  \u001B[38;5;66;03m# UNet(...), # DiffusionSchedule(...)\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/vct/lib/python3.8/site-packages/diffusers/pipelines/pipeline_loading_utils.py:476\u001B[0m, in \u001B[0;36mload_sub_model\u001B[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder)\u001B[0m\n\u001B[1;32m    473\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m load_method(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(cached_folder, name), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloading_kwargs)\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;66;03m# else load from the root directory\u001B[39;00m\n\u001B[0;32m--> 476\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcached_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mloading_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loaded_sub_model\n",
      "File \u001B[0;32m~/miniconda3/envs/vct/lib/python3.8/site-packages/transformers/image_processing_utils.py:161\u001B[0m, in \u001B[0;36mImageProcessingMixin.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_pretrained\u001B[39m(\u001B[38;5;28mcls\u001B[39m, pretrained_model_name_or_path: Union[\u001B[38;5;28mstr\u001B[39m, os\u001B[38;5;241m.\u001B[39mPathLike], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     84\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;124;03m    Instantiate a type of [`~image_processing_utils.ImageProcessingMixin`] from an image processor.\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m    ```\"\"\"\u001B[39;00m\n\u001B[0;32m--> 161\u001B[0m     image_processor_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_image_processor_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_dict(image_processor_dict, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/vct/lib/python3.8/site-packages/transformers/image_processing_utils.py:257\u001B[0m, in \u001B[0;36mImageProcessingMixin.get_image_processor_dict\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    254\u001B[0m image_processor_file \u001B[38;5;241m=\u001B[39m IMAGE_PROCESSOR_NAME\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[0;32m--> 257\u001B[0m     resolved_image_processor_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimage_processor_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001B[39;00m\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;66;03m# the original exception.\u001B[39;00m\n\u001B[1;32m    272\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/vct/lib/python3.8/site-packages/transformers/utils/hub.py:380\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(resolved_file):\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _raise_exceptions_for_missing_entries:\n\u001B[0;32m--> 380\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Checkout \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    382\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available files.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m         )\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: /root/autodl-tmp/LCM does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//root/autodl-tmp/LCM/None' for available files."
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 将 model_path 设置为 Stable-Diffusion-v1.5 的模型路径或名字\n",
    "model_or_name = \"/root/autodl-tmp/LCM\"\n",
    "\n",
    "scheduler = LCMScheduler.from_pretrained(model_or_name, subfolder=\"scheduler\")\n",
    "model = DiffusionPipeline.from_pretrained(\n",
    "    model_or_name, scheduler=scheduler\n",
    ")\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 0\n",
    "generator = torch.Generator(device=device)\n",
    "generator.manual_seed(seed)\n",
    "\n",
    "model.generator = generator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T06:26:36.279077400Z",
     "start_time": "2024-05-14T06:26:35.560139100Z"
    }
   },
   "id": "83810ef29e3285d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 设置一些路径和参数\n",
    "from inversion_free import gen_inversion_free\n",
    "from utils import img2latent, latent2img\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 加载图片\n",
    "# 第一级目录\n",
    "img_dir_src_1 = \"./DVCT/examples\"\n",
    "img_dir_tar_1 = img_dir_src_1\n",
    "# 第二级目录\n",
    "img_dir_src_2 = \"dog\"\n",
    "src_img_dir = os.path.join(img_dir_src_1, img_dir_src_2)\n",
    "tar_img_dir_2 = \"cat_hat\"\n",
    "tar_img_dir = os.path.join(img_dir_tar_1, tar_img_dir_2)\n",
    "\n",
    "def get_image_file(path):\n",
    "    img_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif')\n",
    "    img_files = [f for f in os.listdir(path) if f.lower().endswith(img_extensions)]\n",
    "    return img_files[0]\n",
    "\n",
    "src_img_file = get_image_file(src_img_dir)\n",
    "tar_img_file = get_image_file(tar_img_dir)\n",
    "\n",
    "src_latent = img2latent(os.path.join(src_img_dir, src_img_file), model)\n",
    "tar_latent = img2latent(os.path.join(tar_img_dir, tar_img_file), model)\n",
    "\n",
    "# 加载嵌入向量\n",
    "# 第一级目录\n",
    "embed_dir_src_1 = \"./DVCT/output/\"\n",
    "embed_dir_tar_1 = embed_dir_src_1\n",
    "\n",
    "# 第二级目录\n",
    "embed_dir_src_2 = \"dog\"\n",
    "embed_dir_src_2 = os.path.join(embed_dir_src_1, embed_dir_src_2)\n",
    "tar_embed_dir_2 = \"cat_hat\"\n",
    "tar_embed_dir_2 = os.path.join(embed_dir_tar_1, tar_embed_dir_2)\n",
    "\n",
    "# 嵌入向量名字\n",
    "src_embed_dir = \"dog_05_08_2024_1919\"\n",
    "src_embed_dir = os.path.join(embed_dir_src_2, src_embed_dir)\n",
    "tar_embed_dir = \"cat_hat_05_08_2024_2045\"\n",
    "tar_embed_dir = os.path.join(tar_embed_dir_2, tar_embed_dir)\n",
    "\n",
    "# 嵌入向量训练步数\n",
    "src_steps = 1000\n",
    "tar_steps = src_steps\n",
    "\n",
    "src_embedding = torch.load(os.path.join(src_embed_dir, f\"{src_steps}.bin\"))\n",
    "tar_embedding = torch.load(os.path.join(tar_embed_dir, f\"{tar_steps}.bin\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a46f549390fc345",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils import load_multitoken_tokenizer\n",
    "from multi_token_clip import MultiTokenCLIPTokenizer\n",
    "from transformers.models.clip.modeling_clip import CLIPTextModel\n",
    "\n",
    "src_placeholders = \"<src>\"\n",
    "tar_placeholders = \"<tar>\"\n",
    "\n",
    "text_encoder = CLIPTextModel.from_pretrained(model_or_name, subfolder=\"text_encoder\", revision=False)\n",
    "tokenizer = MultiTokenCLIPTokenizer.from_pretrained(model_or_name, subfolder=\"tokenizer\")\n",
    "\n",
    "placeholder_dict = {\n",
    "    \"<src>\": src_embedding[0][:3],\n",
    "    \"<tar>\": tar_embedding[0][:3],\n",
    "}\n",
    "\n",
    "load_multitoken_tokenizer(tokenizer, text_encoder, placeholder_dict, tar_placeholders)\n",
    "load_multitoken_tokenizer(tokenizer, text_encoder, placeholder_dict, src_placeholders)\n",
    "\n",
    "model.text_encoder = text_encoder\n",
    "model.tokenizer = tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73d9d810e9b79d4f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from attention_control import make_controller\n",
    "\n",
    "# 设置输出目录并生成\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "output_dir = f\"./output_img/{str(date)}-{img_dir_src_2}-to-{tar_img_dir_2}-LCM/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "num_inference_steps = 20\n",
    "save_all = False\n",
    "\n",
    "for attn in [False]:\n",
    "    for cfg in [0.7, 1.7, 2.7]:\n",
    "        # 是否使用注意力控制器\n",
    "        use_attention = attn\n",
    "        \n",
    "        # 选择权重的类型\n",
    "        inclination = \"none-tar\"\n",
    "        mode = \"cosine\"\n",
    "        cfg_guidance_scale = cfg\n",
    "        \n",
    "        # src 和 tar 方向的系数\n",
    "        src_coefficient = 0\n",
    "        tar_coefficient = 0\n",
    "        \n",
    "        output_img_name = f\"{time}_{src_img_file[:-4]}2{tar_img_file[:-4]}_{num_inference_steps}steps_{inclination}_{mode[:3]}_cfg{cfg_guidance_scale}_src{src_coefficient}_tar{tar_coefficient}_attn{use_attention}\"\n",
    "        \n",
    "        if use_attention:\n",
    "            # 设置注意力控制器\n",
    "            placeholder = [src_placeholders, tar_placeholders]\n",
    "            cross_injection_ratio = 0.2\n",
    "            self_injection_ratio = 0.7\n",
    "            eq_param = {\n",
    "                'words' : (placeholder[-1],),\n",
    "                'values' : (0.5,),\n",
    "            }\n",
    "            controller = make_controller(\n",
    "                prompts=placeholder,\n",
    "                tokenizer=tokenizer,\n",
    "                is_replace_controller=False,\n",
    "                cross_replace_steps={'default_': cross_injection_ratio},\n",
    "                self_replace_steps=self_injection_ratio,\n",
    "                equilizer_params=eq_param,\n",
    "            )\n",
    "            model_2 = None\n",
    "        else:\n",
    "            controller = None\n",
    "            model_2 = None\n",
    "            \n",
    "        # 生成图片\n",
    "        latents = gen_inversion_free(\n",
    "            model.to(device), src_latent, tar_latent, src_embedding, tar_embedding,\n",
    "            num_inference_steps=num_inference_steps, mode=mode, inclination=inclination,\n",
    "            cfg_guidance=cfg_guidance_scale, src_coef=src_coefficient, tar_coef=tar_coefficient,\n",
    "            controller=controller, model_2=model_2, return_all=save_all,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        if save_all:\n",
    "            for i, latent in enumerate(latents):\n",
    "                img = latent2img(latent[0].detach(), model)\n",
    "                print(f\"Saving {output_img_name}_{i}.png in {output_dir}\")\n",
    "                img.save(os.path.join(output_dir, f\"{output_img_name}_{i}.png\"))\n",
    "        else:\n",
    "            img = latent2img(latents[-1].detach(), model)\n",
    "            print(f\"Saving {output_img_name}.png in {output_dir}\")\n",
    "            img.save(os.path.join(output_dir, f\"{output_img_name}.png\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d163cc670ff39824"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
